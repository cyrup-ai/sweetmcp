//! Core optimization operations structures and management
//!
//! This module provides the core optimization executor with zero allocation
//! patterns and blazing-fast performance for memory optimization operations.

use std::collections::HashMap;
use std::time::{Duration, Instant, SystemTime};
use tracing::{debug, info, warn};

use crate::utils::{Result, error::Error};
use super::{
    optimization_recommendations::{OptimizationRecommendation, RecommendationType, AnalysisResults},
    health_check::{HealthCheckReport, HealthIssue, IssueSeverity, PerformanceMetrics, ResourceUtilization},
};
use super::super::{
    semantic_item::SemanticItem,
    semantic_relationship::SemanticRelationship,
    memory_manager_core::MemoryStatistics,
};

/// Memory optimization executor with zero allocation patterns
pub struct OptimizationExecutor {
    /// Current optimization strategy
    strategy: OptimizationStrategy,
    /// Execution metrics
    metrics: ExecutionMetrics,
    /// Operation cache for performance
    operation_cache: OperationCache,
    /// Safety constraints
    safety_constraints: SafetyConstraints,
}

impl OptimizationExecutor {
    /// Create new optimization executor with zero allocation optimizations
    #[inline]
    pub fn new(strategy: OptimizationStrategy) -> Self {
        Self {
            strategy,
            metrics: ExecutionMetrics::new(),
            operation_cache: OperationCache::new(),
            safety_constraints: SafetyConstraints::default(),
        }
    }

    /// Create with custom safety constraints
    #[inline]
    pub fn with_constraints(strategy: OptimizationStrategy, constraints: SafetyConstraints) -> Self {
        Self {
            strategy,
            metrics: ExecutionMetrics::new(),
            operation_cache: OperationCache::new(),
            safety_constraints: constraints,
        }
    }

    /// Create with custom cache capacity
    #[inline]
    pub fn with_cache_capacity(strategy: OptimizationStrategy, cache_capacity: usize) -> Self {
        Self {
            strategy,
            metrics: ExecutionMetrics::new(),
            operation_cache: OperationCache::with_capacity(cache_capacity),
            safety_constraints: SafetyConstraints::default(),
        }
    }

    /// Get current strategy
    #[inline]
    pub fn strategy(&self) -> &OptimizationStrategy {
        &self.strategy
    }

    /// Update optimization strategy
    #[inline]
    pub fn set_strategy(&mut self, strategy: OptimizationStrategy) {
        self.strategy = strategy;
    }

    /// Get execution metrics
    #[inline]
    pub fn metrics(&self) -> &ExecutionMetrics {
        &self.metrics
    }

    /// Get safety constraints
    #[inline]
    pub fn safety_constraints(&self) -> &SafetyConstraints {
        &self.safety_constraints
    }

    /// Update safety constraints
    #[inline]
    pub fn set_safety_constraints(&mut self, constraints: SafetyConstraints) {
        self.safety_constraints = constraints;
    }

    /// Clear operation cache
    #[inline]
    pub fn clear_cache(&mut self) {
        self.operation_cache.clear();
    }

    /// Get cache statistics
    #[inline]
    pub fn cache_stats(&self) -> CacheStatistics {
        self.operation_cache.statistics()
    }

    /// Check if executor is ready for optimization
    #[inline]
    pub fn is_ready(&self) -> bool {
        self.strategy.is_valid() && self.safety_constraints.are_satisfied()
    }

    /// Reset execution metrics
    #[inline]
    pub fn reset_metrics(&mut self) {
        self.metrics.reset();
    }
}

/// Optimization strategy configuration
#[derive(Debug, Clone, PartialEq)]
pub struct OptimizationStrategy {
    /// Maximum execution time per optimization
    pub max_execution_time: Duration,
    /// Maximum number of operations to execute
    pub max_operations: usize,
    /// Minimum improvement threshold to continue
    pub min_improvement_threshold: f64,
    /// Enable aggressive optimizations
    pub enable_aggressive_mode: bool,
    /// Enable parallel execution
    pub enable_parallel_execution: bool,
    /// Priority ordering for optimization types
    pub priority_order: Vec<RecommendationType>,
    /// Stop early if improvement target reached
    pub early_stop_threshold: f64,
}

impl OptimizationStrategy {
    /// Create conservative optimization strategy
    #[inline]
    pub fn conservative() -> Self {
        Self {
            max_execution_time: Duration::from_secs(30),
            max_operations: 10,
            min_improvement_threshold: 1.0,
            enable_aggressive_mode: false,
            enable_parallel_execution: false,
            priority_order: vec![
                RecommendationType::CacheOptimization,
                RecommendationType::IndexOptimization,
                RecommendationType::Compression,
            ],
            early_stop_threshold: 10.0,
        }
    }

    /// Create balanced optimization strategy
    #[inline]
    pub fn balanced() -> Self {
        Self {
            max_execution_time: Duration::from_secs(60),
            max_operations: 25,
            min_improvement_threshold: 0.5,
            enable_aggressive_mode: false,
            enable_parallel_execution: true,
            priority_order: vec![
                RecommendationType::Defragmentation,
                RecommendationType::CacheOptimization,
                RecommendationType::IndexOptimization,
                RecommendationType::Compression,
                RecommendationType::RelationshipPruning,
            ],
            early_stop_threshold: 20.0,
        }
    }

    /// Create aggressive optimization strategy
    #[inline]
    pub fn aggressive() -> Self {
        Self {
            max_execution_time: Duration::from_secs(120),
            max_operations: 50,
            min_improvement_threshold: 0.1,
            enable_aggressive_mode: true,
            enable_parallel_execution: true,
            priority_order: vec![
                RecommendationType::Defragmentation,
                RecommendationType::MemoryReallocation,
                RecommendationType::DataStructureOptimization,
                RecommendationType::CacheOptimization,
                RecommendationType::IndexOptimization,
                RecommendationType::Compression,
                RecommendationType::RelationshipPruning,
                RecommendationType::AccessPatternOptimization,
                RecommendationType::GarbageCollectionOptimization,
                RecommendationType::MemoryPoolOptimization,
            ],
            early_stop_threshold: 50.0,
        }
    }

    /// Check if strategy is valid
    #[inline]
    pub fn is_valid(&self) -> bool {
        self.max_execution_time > Duration::from_secs(0) &&
        self.max_operations > 0 &&
        self.min_improvement_threshold >= 0.0 &&
        !self.priority_order.is_empty()
    }

    /// Get timeout for single operation
    #[inline]
    pub fn operation_timeout(&self) -> Duration {
        Duration::from_millis(
            self.max_execution_time.as_millis() as u64 / self.max_operations.max(1) as u64
        )
    }
}

impl Default for OptimizationStrategy {
    fn default() -> Self {
        Self::balanced()
    }
}

/// Execution metrics for optimization operations
#[derive(Debug, Clone)]
pub struct ExecutionMetrics {
    /// Total executions performed
    pub total_executions: usize,
    /// Total improvement achieved
    pub total_improvement: f64,
    /// Total execution time
    pub total_execution_time: Duration,
    /// Average improvement per execution
    pub average_improvement: f64,
    /// Average execution time per operation
    pub average_execution_time: Duration,
    /// Success rate
    pub success_rate: f64,
    /// Last execution timestamp
    pub last_execution: Option<SystemTime>,
    /// Execution history (limited to recent entries)
    execution_history: Vec<ExecutionRecord>,
}

impl ExecutionMetrics {
    /// Create new execution metrics
    #[inline]
    pub fn new() -> Self {
        Self {
            total_executions: 0,
            total_improvement: 0.0,
            total_execution_time: Duration::from_secs(0),
            average_improvement: 0.0,
            average_execution_time: Duration::from_secs(0),
            success_rate: 0.0,
            last_execution: None,
            execution_history: Vec::with_capacity(100), // Keep last 100 executions
        }
    }

    /// Record execution results
    #[inline]
    pub fn record_execution(&mut self, operations_count: usize, improvement: f64, execution_time: Duration) {
        self.total_executions += 1;
        self.total_improvement += improvement;
        self.total_execution_time += execution_time;
        self.last_execution = Some(SystemTime::now());

        // Update averages
        self.average_improvement = self.total_improvement / self.total_executions as f64;
        self.average_execution_time = self.total_execution_time / self.total_executions as u32;

        // Record execution for history
        let record = ExecutionRecord {
            timestamp: SystemTime::now(),
            operations_count,
            improvement,
            execution_time,
            success: true,
        };

        // Maintain history size limit
        if self.execution_history.len() >= 100 {
            self.execution_history.remove(0);
        }
        self.execution_history.push(record);

        // Update success rate
        let successful_executions = self.execution_history.iter()
            .filter(|r| r.success)
            .count();
        self.success_rate = successful_executions as f64 / self.execution_history.len() as f64;
    }

    /// Record failed execution
    #[inline]
    pub fn record_failure(&mut self, execution_time: Duration) {
        self.total_executions += 1;
        self.total_execution_time += execution_time;
        self.last_execution = Some(SystemTime::now());

        // Update averages
        self.average_execution_time = self.total_execution_time / self.total_executions as u32;

        // Record failure for history
        let record = ExecutionRecord {
            timestamp: SystemTime::now(),
            operations_count: 0,
            improvement: 0.0,
            execution_time,
            success: false,
        };

        // Maintain history size limit
        if self.execution_history.len() >= 100 {
            self.execution_history.remove(0);
        }
        self.execution_history.push(record);

        // Update success rate
        let successful_executions = self.execution_history.iter()
            .filter(|r| r.success)
            .count();
        self.success_rate = successful_executions as f64 / self.execution_history.len() as f64;
    }

    /// Reset all metrics
    #[inline]
    pub fn reset(&mut self) {
        self.total_executions = 0;
        self.total_improvement = 0.0;
        self.total_execution_time = Duration::from_secs(0);
        self.average_improvement = 0.0;
        self.average_execution_time = Duration::from_secs(0);
        self.success_rate = 0.0;
        self.last_execution = None;
        self.execution_history.clear();
    }

    /// Get recent execution history
    #[inline]
    pub fn recent_history(&self, count: usize) -> &[ExecutionRecord] {
        let start = self.execution_history.len().saturating_sub(count);
        &self.execution_history[start..]
    }

    /// Get performance trend
    #[inline]
    pub fn performance_trend(&self) -> PerformanceTrend {
        if self.execution_history.len() < 2 {
            return PerformanceTrend::Stable;
        }

        let recent_count = (self.execution_history.len() / 2).max(1);
        let recent_avg = self.execution_history.iter()
            .rev()
            .take(recent_count)
            .map(|r| r.improvement)
            .sum::<f64>() / recent_count as f64;

        let older_avg = self.execution_history.iter()
            .take(self.execution_history.len() - recent_count)
            .map(|r| r.improvement)
            .sum::<f64>() / (self.execution_history.len() - recent_count) as f64;

        let improvement_ratio = recent_avg / older_avg.max(0.001);

        if improvement_ratio > 1.1 {
            PerformanceTrend::Improving
        } else if improvement_ratio < 0.9 {
            PerformanceTrend::Declining
        } else {
            PerformanceTrend::Stable
        }
    }
}

impl Default for ExecutionMetrics {
    fn default() -> Self {
        Self::new()
    }
}

/// Individual execution record
#[derive(Debug, Clone)]
pub struct ExecutionRecord {
    pub timestamp: SystemTime,
    pub operations_count: usize,
    pub improvement: f64,
    pub execution_time: Duration,
    pub success: bool,
}

/// Performance trend enumeration
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum PerformanceTrend {
    Improving,
    Stable,
    Declining,
}

/// Operation cache for performance optimization
#[derive(Debug)]
pub struct OperationCache {
    /// Cache entries
    entries: HashMap<RecommendationType, CachedResult>,
    /// Cache capacity
    capacity: usize,
    /// Cache statistics
    stats: CacheStatistics,
}

impl OperationCache {
    /// Create new operation cache
    #[inline]
    pub fn new() -> Self {
        Self::with_capacity(50)
    }

    /// Create cache with specific capacity
    #[inline]
    pub fn with_capacity(capacity: usize) -> Self {
        Self {
            entries: HashMap::with_capacity(capacity),
            capacity,
            stats: CacheStatistics::new(),
        }
    }

    /// Get cached result
    #[inline]
    pub fn get(&mut self, recommendation_type: &RecommendationType) -> Option<&CachedResult> {
        match self.entries.get(recommendation_type) {
            Some(cached) => {
                self.stats.record_hit();
                Some(cached)
            }
            None => {
                self.stats.record_miss();
                None
            }
        }
    }

    /// Insert result into cache
    #[inline]
    pub fn insert(&mut self, recommendation_type: RecommendationType, result: SingleOptimizationResult) {
        // Evict oldest entry if at capacity
        if self.entries.len() >= self.capacity {
            if let Some(oldest_key) = self.find_oldest_entry() {
                self.entries.remove(&oldest_key);
            }
        }

        let cached_result = CachedResult {
            result,
            timestamp: SystemTime::now(),
        };

        self.entries.insert(recommendation_type, cached_result);
    }

    /// Clear all cache entries
    #[inline]
    pub fn clear(&mut self) {
        self.entries.clear();
        self.stats.reset();
    }

    /// Get cache statistics
    #[inline]
    pub fn statistics(&self) -> CacheStatistics {
        self.stats.clone()
    }

    /// Find oldest cache entry for eviction
    #[inline]
    fn find_oldest_entry(&self) -> Option<RecommendationType> {
        self.entries.iter()
            .min_by_key(|(_, cached)| cached.timestamp)
            .map(|(key, _)| key.clone())
    }
}

impl Default for OperationCache {
    fn default() -> Self {
        Self::new()
    }
}

/// Cached optimization result
#[derive(Debug, Clone)]
pub struct CachedResult {
    pub result: SingleOptimizationResult,
    pub timestamp: SystemTime,
}

impl CachedResult {
    /// Check if cached result is still recent
    #[inline]
    pub fn is_recent(&self) -> bool {
        self.timestamp.elapsed()
            .map(|elapsed| elapsed < Duration::from_secs(300)) // 5 minutes
            .unwrap_or(false)
    }

    /// Get age of cached result
    #[inline]
    pub fn age(&self) -> Duration {
        self.timestamp.elapsed().unwrap_or(Duration::from_secs(0))
    }
}

/// Cache performance statistics
#[derive(Debug, Clone)]
pub struct CacheStatistics {
    pub hits: usize,
    pub misses: usize,
    pub hit_rate: f64,
}

impl CacheStatistics {
    /// Create new cache statistics
    #[inline]
    pub fn new() -> Self {
        Self {
            hits: 0,
            misses: 0,
            hit_rate: 0.0,
        }
    }

    /// Record cache hit
    #[inline]
    pub fn record_hit(&mut self) {
        self.hits += 1;
        self.update_hit_rate();
    }

    /// Record cache miss
    #[inline]
    pub fn record_miss(&mut self) {
        self.misses += 1;
        self.update_hit_rate();
    }

    /// Reset statistics
    #[inline]
    pub fn reset(&mut self) {
        self.hits = 0;
        self.misses = 0;
        self.hit_rate = 0.0;
    }

    /// Update hit rate calculation
    #[inline]
    fn update_hit_rate(&mut self) {
        let total = self.hits + self.misses;
        self.hit_rate = if total > 0 {
            self.hits as f64 / total as f64
        } else {
            0.0
        };
    }
}

impl Default for CacheStatistics {
    fn default() -> Self {
        Self::new()
    }
}

/// Safety constraints for optimization operations
#[derive(Debug, Clone)]
pub struct SafetyConstraints {
    /// Maximum memory usage allowed during optimization
    pub max_memory_usage: usize,
    /// Maximum CPU usage percentage
    pub max_cpu_usage: f64,
    /// Require backup before destructive operations
    pub require_backup: bool,
    /// Enable rollback on failure
    pub enable_rollback: bool,
    /// Maximum items to process in single operation
    pub max_items_per_operation: usize,
    /// Timeout for individual operations
    pub operation_timeout: Duration,
}

impl SafetyConstraints {
    /// Create strict safety constraints
    #[inline]
    pub fn strict() -> Self {
        Self {
            max_memory_usage: 1024 * 1024 * 100, // 100MB
            max_cpu_usage: 50.0,
            require_backup: true,
            enable_rollback: true,
            max_items_per_operation: 1000,
            operation_timeout: Duration::from_secs(30),
        }
    }

    /// Create relaxed safety constraints
    #[inline]
    pub fn relaxed() -> Self {
        Self {
            max_memory_usage: 1024 * 1024 * 500, // 500MB
            max_cpu_usage: 80.0,
            require_backup: false,
            enable_rollback: true,
            max_items_per_operation: 10000,
            operation_timeout: Duration::from_secs(120),
        }
    }

    /// Check if constraints are satisfied
    #[inline]
    pub fn are_satisfied(&self) -> bool {
        self.max_memory_usage > 0 &&
        self.max_cpu_usage > 0.0 &&
        self.max_items_per_operation > 0 &&
        self.operation_timeout > Duration::from_secs(0)
    }
}

impl Default for SafetyConstraints {
    fn default() -> Self {
        Self {
            max_memory_usage: 1024 * 1024 * 200, // 200MB
            max_cpu_usage: 70.0,
            require_backup: false,
            enable_rollback: true,
            max_items_per_operation: 5000,
            operation_timeout: Duration::from_secs(60),
        }
    }
}

/// Single optimization operation result
#[derive(Debug, Clone)]
pub struct SingleOptimizationResult {
    pub recommendation_type: RecommendationType,
    pub improvement_achieved: f64,
    pub description: String,
    pub success: bool,
    pub execution_time: Duration,
    pub items_processed: usize,
    pub memory_saved: usize,
}

impl SingleOptimizationResult {
    /// Create new optimization result
    #[inline]
    pub fn new(
        recommendation_type: RecommendationType,
        improvement_achieved: f64,
        description: String,
        success: bool,
    ) -> Self {
        Self {
            recommendation_type,
            improvement_achieved,
            description,
            success,
            execution_time: Duration::from_secs(0),
            items_processed: 0,
            memory_saved: 0,
        }
    }

    /// Create with full details
    #[inline]
    pub fn with_details(
        recommendation_type: RecommendationType,
        improvement_achieved: f64,
        description: String,
        success: bool,
        execution_time: Duration,
        items_processed: usize,
        memory_saved: usize,
    ) -> Self {
        Self {
            recommendation_type,
            improvement_achieved,
            description,
            success,
            execution_time,
            items_processed,
            memory_saved,
        }
    }

    /// Check if result represents significant improvement
    #[inline]
    pub fn is_significant(&self) -> bool {
        self.success && self.improvement_achieved >= 1.0
    }

    /// Get efficiency score (improvement per second)
    #[inline]
    pub fn efficiency_score(&self) -> f64 {
        if self.execution_time.as_secs_f64() > 0.0 {
            self.improvement_achieved / self.execution_time.as_secs_f64()
        } else {
            0.0
        }
    }
}

/// Overall optimization execution result
#[derive(Debug, Clone)]
pub struct OptimizationResult {
    pub individual_results: Vec<SingleOptimizationResult>,
    pub total_improvement: f64,
    pub total_execution_time: Duration,
    pub efficiency_score: f64,
    pub success_rate: f64,
    pub total_memory_saved: usize,
    pub total_items_processed: usize,
}

impl OptimizationResult {
    /// Create new optimization result
    #[inline]
    pub fn new(
        individual_results: Vec<SingleOptimizationResult>,
        total_improvement: f64,
        total_execution_time: Duration,
        efficiency_score: f64,
    ) -> Self {
        let success_count = individual_results.iter().filter(|r| r.success).count();
        let success_rate = if individual_results.is_empty() {
            0.0
        } else {
            success_count as f64 / individual_results.len() as f64
        };

        let total_memory_saved = individual_results.iter()
            .map(|r| r.memory_saved)
            .sum();

        let total_items_processed = individual_results.iter()
            .map(|r| r.items_processed)
            .sum();

        Self {
            individual_results,
            total_improvement,
            total_execution_time,
            efficiency_score,
            success_rate,
            total_memory_saved,
            total_items_processed,
        }
    }

    /// Check if optimization was successful overall
    #[inline]
    pub fn is_successful(&self) -> bool {
        self.success_rate >= 0.5 && self.total_improvement > 0.0
    }

    /// Get summary description
    #[inline]
    pub fn summary(&self) -> String {
        format!(
            "Optimization completed: {:.1}% improvement, {:.1}% success rate, {} operations in {:?}",
            self.total_improvement,
            self.success_rate * 100.0,
            self.individual_results.len(),
            self.total_execution_time
        )
    }
}